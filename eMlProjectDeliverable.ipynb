{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1958932,
          "sourceType": "datasetVersion",
          "datasetId": 1169316
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iness000/Recipe-Generation-Based-on-Given-Ingredients/blob/main/eMlProjectDeliverable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Recipe Generation Based on Given Ingredients**"
      ],
      "metadata": {
        "id": "3BfP4q6IfhYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment overview"
      ],
      "metadata": {
        "id": "gdQDj1udLqu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "   This project aims to develop a model that can generate cooking recipes based on a list of provided ingredients. We'll use a Transformer-based architecture, a powerful deep learning model well-suited for sequence-to-sequence tasks.\n",
        "\n",
        "   In essence,we used a powerful combination of deep learning libraries (PyTorch, Transformers) and data processing tools (Pandas, SentencePiece, Rouge-Score) to build and evaluate a recipe generation model."
      ],
      "metadata": {
        "id": "48OyawZ5Lsgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformer Architecture**"
      ],
      "metadata": {
        "id": "qTouu98kfisU"
      }
    },
    {
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "fYLyO6vys3LE",
        "outputId": "9dc04b72-7996-48c9-a51e-724d42a0977a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "wvJdGcsTseb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9491df21-9916-4cf4-8391-751580d9ad75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Food Ingredients and Recipe Dataset with Image Name Mapping.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display dataset structure\n",
        "print(data.info())\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-07T21:23:24.787879Z",
          "iopub.execute_input": "2024-12-07T21:23:24.788357Z",
          "iopub.status.idle": "2024-12-07T21:23:31.454565Z",
          "shell.execute_reply.started": "2024-12-07T21:23:24.788306Z",
          "shell.execute_reply": "2024-12-07T21:23:31.453413Z"
        },
        "id": "bRgLULOXseb6",
        "outputId": "cbb3a23c-b97c-44d4-9139-77779010cf53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13501 entries, 0 to 13500\n",
            "Data columns (total 6 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   Unnamed: 0           13501 non-null  int64 \n",
            " 1   Title                13496 non-null  object\n",
            " 2   Ingredients          13501 non-null  object\n",
            " 3   Instructions         13493 non-null  object\n",
            " 4   Image_Name           13501 non-null  object\n",
            " 5   Cleaned_Ingredients  13501 non-null  object\n",
            "dtypes: int64(1), object(5)\n",
            "memory usage: 633.0+ KB\n",
            "None\n",
            "   Unnamed: 0                                              Title  \\\n",
            "0           0  Miso-Butter Roast Chicken With Acorn Squash Pa...   \n",
            "1           1                    Crispy Salt and Pepper Potatoes   \n",
            "2           2                        Thanksgiving Mac and Cheese   \n",
            "3           3                 Italian Sausage and Bread Stuffing   \n",
            "4           4                                       Newton's Law   \n",
            "\n",
            "                                         Ingredients  \\\n",
            "0  ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...   \n",
            "1  ['2 large egg whites', '1 pound new potatoes (...   \n",
            "2  ['1 cup evaporated milk', '1 cup whole milk', ...   \n",
            "3  ['1 (¾- to 1-pound) round Italian loaf, cut in...   \n",
            "4  ['1 teaspoon dark brown sugar', '1 teaspoon ho...   \n",
            "\n",
            "                                        Instructions  \\\n",
            "0  Pat chicken dry with paper towels, season all ...   \n",
            "1  Preheat oven to 400°F and line a rimmed baking...   \n",
            "2  Place a rack in middle of oven; preheat to 400...   \n",
            "3  Preheat oven to 350°F with rack in middle. Gen...   \n",
            "4  Stir together brown sugar and hot water in a c...   \n",
            "\n",
            "                                          Image_Name  \\\n",
            "0  miso-butter-roast-chicken-acorn-squash-panzanella   \n",
            "1         crispy-salt-and-pepper-potatoes-dan-kluger   \n",
            "2         thanksgiving-mac-and-cheese-erick-williams   \n",
            "3          italian-sausage-and-bread-stuffing-240559   \n",
            "4                 newtons-law-apple-bourbon-cocktail   \n",
            "\n",
            "                                 Cleaned_Ingredients  \n",
            "0  ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...  \n",
            "1  ['2 large egg whites', '1 pound new potatoes (...  \n",
            "2  ['1 cup evaporated milk', '1 cup whole milk', ...  \n",
            "3  ['1 (¾- to 1-pound) round Italian loaf, cut in...  \n",
            "4  ['1 teaspoon dark brown sugar', '1 teaspoon ho...  \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning**"
      ],
      "metadata": {
        "id": "w21OzxJGseb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Dropped unnecessary columns ( \"Ingredients\", and \"Image_Name\") to focus on the essential data: Cleaned_Ingredients and Instructions.\n",
        "* Filled missing values in Title, Instructions, and Cleaned_Ingredients to prevent issues during tokenization and embedding.\n",
        "* Cleaned and normalized text data\n",
        "*  Convert  columns to strings"
      ],
      "metadata": {
        "id": "dpoJ87oJseb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KeQo-Fwfseb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary column\n",
        "\n",
        "data = data.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\") # Changed 'df' to 'data'\n",
        "columns_to_drop = [\"Ingredients\", \"Image_Name\"]  # Drop raw ingredients and image names\n",
        "data = data.drop(columns=columns_to_drop, errors=\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Clean and normalize text in Cleaned_Ingredients\n",
        "data['Cleaned_Ingredients'] = data['Cleaned_Ingredients'].str.replace(r\"[^a-zA-Z0-9, ]\", \"\", regex=True).str.lower()\n",
        "data['Instructions'] = data['Instructions'].str.replace(r\"[^a-zA-Z0-9, ]\", \"\", regex=True).str.lower()\n",
        "\n",
        "# Check the cleaned data\n",
        "print(data.head())\n",
        "print(data.info())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-07T21:23:31.456691Z",
          "iopub.execute_input": "2024-12-07T21:23:31.457089Z",
          "iopub.status.idle": "2024-12-07T21:23:31.889409Z",
          "shell.execute_reply.started": "2024-12-07T21:23:31.457053Z",
          "shell.execute_reply": "2024-12-07T21:23:31.888337Z"
        },
        "id": "ZfdgzD2Qseb7",
        "outputId": "3817354b-ce97-4074-db1b-2fdb55674f12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Title  \\\n",
            "0  Miso-Butter Roast Chicken With Acorn Squash Pa...   \n",
            "1                    Crispy Salt and Pepper Potatoes   \n",
            "2                        Thanksgiving Mac and Cheese   \n",
            "3                 Italian Sausage and Bread Stuffing   \n",
            "4                                       Newton's Law   \n",
            "\n",
            "                                        Instructions  \\\n",
            "0  pat chicken dry with paper towels, season all ...   \n",
            "1  preheat oven to 400f and line a rimmed baking ...   \n",
            "2  place a rack in middle of oven preheat to 400 ...   \n",
            "3  preheat oven to 350f with rack in middle gener...   \n",
            "4  stir together brown sugar and hot water in a c...   \n",
            "\n",
            "                                 Cleaned_Ingredients  \n",
            "0  1 34lb whole chicken, 2 tsp kosher salt, divid...  \n",
            "1  2 large egg whites, 1 pound new potatoes about...  \n",
            "2  1 cup evaporated milk, 1 cup whole milk, 1 tsp...  \n",
            "3  1  to 1pound round italian loaf, cut into 1inc...  \n",
            "4  1 teaspoon dark brown sugar, 1 teaspoon hot wa...  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13501 entries, 0 to 13500\n",
            "Data columns (total 3 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   Title                13496 non-null  object\n",
            " 1   Instructions         13493 non-null  object\n",
            " 2   Cleaned_Ingredients  13501 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 316.6+ KB\n",
            "None\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyTr9ROZavkz",
        "outputId": "d80995df-248b-40e9-d1fb-734454ba6665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13501 entries, 0 to 13500\n",
            "Data columns (total 3 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   Title                13496 non-null  object\n",
            " 1   Instructions         13493 non-null  object\n",
            " 2   Cleaned_Ingredients  13501 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 316.6+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values\n",
        "\n",
        "\n",
        "data['Title'] = data['Title'].fillna(\"Unknown Recipe\")\n",
        "\n",
        "# Drop rows Cleaned_Ingredients is missing\n",
        "data = data[~data['Cleaned_Ingredients'].isnull() & (data['Cleaned_Ingredients'].str.strip() != \"\")]\n",
        "data = data[~data['Instructions'].isnull() & (data['Instructions'].str.strip() != \"\")]"
      ],
      "metadata": {
        "id": "F_30wME6e0ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZ8K9NcSefmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**verification**"
      ],
      "metadata": {
        "id": "E_EIWHa_seb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check if any empty Cleaned_Ingredients remain\n",
        "empty_ingredients = data[data['Cleaned_Ingredients'].isnull() | (data['Cleaned_Ingredients'].str.strip() == \"\")]\n",
        "missing_instructions = data['Instructions'].isnull().sum()\n",
        "missing_title = data['Title'].isnull().sum()\n",
        "\n",
        "print(f\"Number of missing (null) values in Instructions: {missing_instructions}\")\n",
        "print(f\"Number of missing (null) values in Title: {missing_title}\")\n",
        "print(\"Remaining rows with empty Cleaned_Ingredients:\", empty_ingredients.shape[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-07T21:23:31.890603Z",
          "iopub.execute_input": "2024-12-07T21:23:31.890892Z",
          "iopub.status.idle": "2024-12-07T21:23:31.911143Z",
          "shell.execute_reply.started": "2024-12-07T21:23:31.890865Z",
          "shell.execute_reply": "2024-12-07T21:23:31.909925Z"
        },
        "id": "FlLDaNKtseb7",
        "outputId": "f1b7d319-daf0-4899-b5d5-7a05bc9ae9e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing (null) values in Instructions: 0\n",
            "Number of missing (null) values in Title: 0\n",
            "Remaining rows with empty Cleaned_Ingredients: 0\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert specific columns to strings\n",
        "columns_to_convert = [\"Title\", \"Instructions\", \"Cleaned_Ingredients\"]\n",
        "data[columns_to_convert] = data[columns_to_convert].astype('string')  # Change to 'string' dtype\n",
        "\n",
        "# Confirm conversion\n",
        "print(data.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SE4J-pefEW2",
        "outputId": "a17f8cea-356c-471d-e841-2905aedabf4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title                  string[python]\n",
            "Instructions           string[python]\n",
            "Cleaned_Ingredients    string[python]\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**"
      ],
      "metadata": {
        "id": "y1Ympn9Nseb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Tokenized Cleaned_Ingredients by splitting ingredients into individual tokens\n",
        "* Tokenized Instructions into words for sequential processing by the model.\n",
        "> we don’t need to tokenize recipe titles because they are usually metadata and not directly used as input for a Transformer model."
      ],
      "metadata": {
        "id": "7JkqXhZ7seb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KPNVXrPF0sHT"
      }
    },
    {
      "source": [
        "import re\n",
        "\n",
        "def split_ingredient_components(ingredient):\n",
        "    ingredient = ingredient.lower().strip()\n",
        "    known_units = ['tsp', 'tablespoon', 'tbsp', 'cup', 'cups', 'lb', 'oz', 'g', 'kg', 'ml', 'l', 'can', 'cans', 'pound', 'pounds', 'pinch', 'dash', 'clove']\n",
        "\n",
        "    quantity = \"\"\n",
        "    unit = \"\"\n",
        "    name = \"\"\n",
        "\n",
        "    # Extract quantity using regex\n",
        "    quantity_match = re.search(r\"(\\d+\\s*[\\/\\d\\.]*)\", ingredient)\n",
        "    if quantity_match:\n",
        "        quantity = quantity_match.group(1).strip()\n",
        "        ingredient = ingredient.replace(quantity, \"\").strip()\n",
        "\n",
        "    # Extract unit by checking against known_units\n",
        "    words = ingredient.split()\n",
        "    for i, word in enumerate(words):\n",
        "        if word in known_units:\n",
        "            unit = word\n",
        "            name = \" \".join(words[i + 1:])\n",
        "            break\n",
        "\n",
        "    # If no unit found, assume the entire string is the ingredient name\n",
        "    if not unit:\n",
        "        name = ingredient\n",
        "\n",
        "    return {\"quantity\": quantity, \"unit\": unit, \"ingredient_name\": name}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "dC0JgF7Q57s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "data['Structured_Ingredients'] = data['Cleaned_Ingredients'].apply(\n",
        "       lambda ingredients_string: [split_ingredient_components(ing.strip()) for ing in ingredients_string.split(',') if ing.strip()]\n",
        "   )"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "rYT4P6EK6RsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "print(data['Structured_Ingredients'])\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKJqc64w6geX",
        "outputId": "5a9e904a-b6c3-46ef-addd-f30b2c9586db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        [{'quantity': '1 34', 'unit': 'lb', 'ingredien...\n",
            "1        [{'quantity': '2', 'unit': '', 'ingredient_nam...\n",
            "2        [{'quantity': '1', 'unit': 'cup', 'ingredient_...\n",
            "3        [{'quantity': '1', 'unit': 'pound', 'ingredien...\n",
            "4        [{'quantity': '1', 'unit': '', 'ingredient_nam...\n",
            "                               ...                        \n",
            "13496    [{'quantity': '1', 'unit': 'cup', 'ingredient_...\n",
            "13497    [{'quantity': '1', 'unit': '', 'ingredient_nam...\n",
            "13498    [{'quantity': '1', 'unit': 'cup', 'ingredient_...\n",
            "13499    [{'quantity': '1', 'unit': 'cup', 'ingredient_...\n",
            "13500    [{'quantity': '12', 'unit': 'lb', 'ingredient_...\n",
            "Name: Structured_Ingredients, Length: 13487, dtype: object\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import re\n",
        "\n",
        "# Robust Tokenization Function\n",
        "def tokenize_structured_ingredients(structured_ingredients):\n",
        "    tokenized_data = []\n",
        "\n",
        "    # Verify input is a list\n",
        "    if not isinstance(structured_ingredients, list):\n",
        "        return []  # Return empty list if not a valid list\n",
        "\n",
        "    for ing in structured_ingredients:\n",
        "        if isinstance(ing, dict):\n",
        "             # Extract and tokenize ingredient names\n",
        "\n",
        "            ingredient_name = ing.get(\"ingredient_name\", \"\").strip()\n",
        "\n",
        "\n",
        "            if ingredient_name:\n",
        "                tokens = ingredient_name.split()  # Tokenize by words\n",
        "                tokenized_data.extend(tokens)\n",
        "    return tokenized_data\n",
        "\n",
        "\n",
        "# Apply tokenization to 'Structured_Ingredients'\n",
        "data['Tokenized_Ingredients'] = data['Structured_Ingredients'].apply(tokenize_structured_ingredients)\n",
        "\n",
        "# Inspect the results\n",
        "print(\"Sample Tokenized Ingredients:\")\n",
        "print(data['Tokenized_Ingredients'])\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-fL1gnoH4x-",
        "outputId": "da7e004d-f582-46cb-fcf0-e8571d40d88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Tokenized Ingredients:\n",
            "0        [whole, chicken, kosher, salt, divided, plus, ...\n",
            "1        [large, egg, whites, new, potatoes, about, inc...\n",
            "2        [evaporated, milk, whole, milk, garlic, powder...\n",
            "3        [round, italian, loaf, tablespoons, olive, oil...\n",
            "4        [teaspoon, dark, brown, sugar, teaspoon, hot, ...\n",
            "                               ...                        \n",
            "13496    [allpurpose, flour, unsweetened, cocoa, powder...\n",
            "13497    [preserved, lemon, butternut, squash, peeled, ...\n",
            "13498    [katsuo, bushi, fresh, from, package, sake, te...\n",
            "13499    [plus, tablespoon, unsalted, butter, baby, spi...\n",
            "13500    [whole, tomatoes, including, juice, large, gar...\n",
            "Name: Tokenized_Ingredients, Length: 13487, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize 'Instructions' into lists of words\n",
        "data['Tokenized_Instructions'] = data['Instructions'].apply(lambda x: x.split())\n",
        "\n",
        "\n",
        "print(\"\\nSample Tokenized Instructions:\")\n",
        "print(data['Tokenized_Instructions'].head())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-07T21:23:31.912384Z",
          "iopub.execute_input": "2024-12-07T21:23:31.912701Z",
          "iopub.status.idle": "2024-12-07T21:23:32.433973Z",
          "shell.execute_reply.started": "2024-12-07T21:23:31.912671Z",
          "shell.execute_reply": "2024-12-07T21:23:32.432882Z"
        },
        "outputId": "3ac1d08e-0361-4c30-cc3b-422be9f8fb1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vl9gtJHHUOI"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Tokenized Instructions:\n",
            "0    [pat, chicken, dry, with, paper, towels,, seas...\n",
            "1    [preheat, oven, to, 400f, and, line, a, rimmed...\n",
            "2    [place, a, rack, in, middle, of, oven, preheat...\n",
            "3    [preheat, oven, to, 350f, with, rack, in, midd...\n",
            "4    [stir, together, brown, sugar, and, hot, water...\n",
            "Name: Tokenized_Instructions, dtype: object\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Vocabulary Creation**"
      ],
      "metadata": {
        "id": "wuAoahdKseb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmRIAA1C0BU7",
        "outputId": "d8ad965b-cc14-48b8-9085-0e748dc14595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Tokenized the dataset into subword units using **SentencePiece**.\n",
        "- Combined both `Tokenized_Ingredients` and `Tokenized_Instructions` to train the tokenizer.\n",
        "- Output:\n",
        "  - `recipe.model`: Trained subword tokenizer model.\n",
        "  - `recipe.vocab`: Vocabulary file containing subword units.\n",
        "\n"
      ],
      "metadata": {
        "id": "WB-VeGcLseb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "# Prepare a text file with all the tokenized ingredients and instructions\n",
        "with open(\"corpus.txt\", \"w\") as f:\n",
        "    # Write Tokenized Ingredients\n",
        "    for tokens in data['Tokenized_Ingredients']:\n",
        "        f.write(\" \".join(tokens) + \"\\n\")\n",
        "    # Write Tokenized Instructions\n",
        "    for tokens in data['Tokenized_Instructions']:\n",
        "        f.write(\" \".join(tokens) + \"\\n\")\n",
        "\n",
        "# Train SentencePiece model with the new corpus\n",
        "spm.SentencePieceTrainer.train(input=\"corpus.txt\", model_prefix=\"recipe\", vocab_size=12000 , character_coverage=0.9995  )\n",
        "\n",
        "# Load the trained model\n",
        "sp = spm.SentencePieceProcessor(model_file=\"recipe.model\")\n",
        "\n",
        "# Apply subword tokenization to ingredients and instructions\n",
        "data['Ingredient_Ids'] = data['Tokenized_Ingredients'].apply(lambda x: sp.encode(\" \".join(x), out_type=int , add_bos=True, add_eos=True))\n",
        "data['Instruction_Ids'] = data['Tokenized_Instructions'].apply(lambda x: sp.encode(\" \".join(x), out_type=int, add_bos=True, add_eos=True))\n",
        "\n",
        "# Get the vocabulary size\n",
        "vocab_size = sp.get_piece_size()\n",
        "print(f\"New Vocabulary Size: {vocab_size}\")\n",
        "\n",
        "# Print samples of the tokenized IDs for verification\n",
        "print(\"Sample Ingredient IDs:\")\n",
        "print(data['Ingredient_Ids'].head())\n",
        "\n",
        "print(\"\\nSample Instruction IDs:\")\n",
        "print(data['Instruction_Ids'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K5sA3rc0Bxc",
        "outputId": "27f228a7-4a8a-4ceb-b4fb-bb42c425cd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Vocabulary Size: 12000\n",
            "Sample Ingredient IDs:\n",
            "0    [1, 187, 85, 87, 13, 141, 119, 76, 428, 81, 35...\n",
            "1    [1, 22, 106, 408, 1413, 196, 16, 160, 8, 1126,...\n",
            "2    [1, 999, 147, 187, 147, 53, 145, 95, 145, 709,...\n",
            "3    [1, 357, 579, 736, 24, 71, 18, 141, 439, 579, ...\n",
            "4    [1, 23, 438, 74, 31, 23, 150, 33, 1088, 32, 56...\n",
            "Name: Ingredient_Ids, dtype: object\n",
            "\n",
            "Sample Instruction IDs:\n",
            "0    [1, 483, 85, 128, 9, 169, 436, 3, 79, 118, 20,...\n",
            "1    [1, 140, 47, 5, 505, 63, 4, 411, 7, 27, 275, 4...\n",
            "2    [1, 75, 7, 124, 8, 419, 11, 47, 140, 5, 505, 1...\n",
            "3    [1, 140, 47, 5, 240, 63, 9, 124, 8, 419, 626, ...\n",
            "4    [1, 58, 149, 74, 31, 4, 150, 33, 8, 7, 908, 10...\n",
            "Name: Instruction_Ids, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h59EPhUQ-AsX",
        "outputId": "cac6be17-9d0c-4a4c-eb8c-03c52295088c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **5. Output Readiness Check**"
      ],
      "metadata": {
        "id": "FVZHlyGyseb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze Ingredient and Instruction Lengths\n",
        "ingredient_lengths = data['Ingredient_Ids'].apply(len)\n",
        "instruction_lengths = data['Instruction_Ids'].apply(len)\n",
        "\n",
        "# Print statistics\n",
        "print(\"Ingredient Lengths Statistics:\")\n",
        "print(\"Max:\", ingredient_lengths.max(), \"Min:\", ingredient_lengths.min(), \"Mean:\", ingredient_lengths.mean())\n",
        "\n",
        "print(\"\\nInstruction Lengths Statistics:\")\n",
        "print(\"Max:\", instruction_lengths.max(), \"Min:\", instruction_lengths.min(), \"Mean:\", instruction_lengths.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riVwQpriT0dN",
        "outputId": "7da8e67c-f804-4c04-de9b-8bbff46ed28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredient Lengths Statistics:\n",
            "Max: 352 Min: 3 Mean: 50.89804997404909\n",
            "\n",
            "Instruction Lengths Statistics:\n",
            "Max: 2948 Min: 8 Mean: 201.97820123081485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad/truncate sequences\n",
        "max_ingredient_length = 128\n",
        "max_instruction_length =  1024\n",
        "\n",
        "data['Padded_Ingredient_Ids'] = data['Ingredient_Ids'].apply(\n",
        "    lambda x: x[:max_ingredient_length] + [0] * (max_ingredient_length - len(x))\n",
        ")\n",
        "data['Padded_Instruction_Ids'] = data['Instruction_Ids'].apply(\n",
        "    lambda x: x[:max_instruction_length] + [0] * (max_instruction_length - len(x))\n",
        ")\n",
        "\n",
        "# Verify padded sequences\n",
        "print(\"\\nStep 5: Output Readiness Check Completed\")\n",
        "print(\"Padded Ingredient Lengths:\", len(data['Padded_Ingredient_Ids'][0]))\n",
        "print(\"Padded Instruction Lengths:\", len(data['Padded_Instruction_Ids'][0]))\n",
        "\n",
        "# Step 3: Validate Sequence Length Consistency\n",
        "ingredient_lengths = data['Padded_Ingredient_Ids'].apply(len).unique()\n",
        "instruction_lengths = data['Padded_Instruction_Ids'].apply(len).unique()\n",
        "\n",
        "print(\"\\nUnique Ingredient Sequence Lengths:\", ingredient_lengths)\n",
        "print(\"Unique Instruction Sequence Lengths:\", instruction_lengths)\n",
        "\n",
        "# Step 4: Check for Empty or All-Zero Sequences\n",
        "empty_ingredient_sequences = (data['Padded_Ingredient_Ids'].apply(sum) == 0).sum()\n",
        "empty_instruction_sequences = (data['Padded_Instruction_Ids'].apply(sum) == 0).sum()\n",
        "\n",
        "print(\"\\nNumber of Empty Ingredient Sequences:\", empty_ingredient_sequences)\n",
        "print(\"Number of Empty Instruction Sequences:\", empty_instruction_sequences)\n",
        "\n",
        "# Step 5: Validate Data Types\n",
        "print(\"\\nData Type of Padded Ingredient IDs:\", type(data['Padded_Ingredient_Ids'][0]))\n",
        "print(\"Data Type of Padded Instruction IDs:\", type(data['Padded_Instruction_Ids'][0]))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-07T21:23:34.702082Z",
          "iopub.execute_input": "2024-12-07T21:23:34.7024Z",
          "iopub.status.idle": "2024-12-07T21:23:35.076646Z",
          "shell.execute_reply.started": "2024-12-07T21:23:34.70237Z",
          "shell.execute_reply": "2024-12-07T21:23:35.075464Z"
        },
        "id": "m8qHSTyUseb-",
        "outputId": "68033924-6725-455b-fd1c-2e1c43a21b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 5: Output Readiness Check Completed\n",
            "Padded Ingredient Lengths: 128\n",
            "Padded Instruction Lengths: 1024\n",
            "\n",
            "Unique Ingredient Sequence Lengths: [128]\n",
            "Unique Instruction Sequence Lengths: [1024]\n",
            "\n",
            "Number of Empty Ingredient Sequences: 0\n",
            "Number of Empty Instruction Sequences: 0\n",
            "\n",
            "Data Type of Padded Ingredient IDs: <class 'list'>\n",
            "Data Type of Padded Instruction IDs: <class 'list'>\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why These Specific Lengths Were Chosen:**\n",
        "\n",
        "* Ingredients: Max length is 350, mean is 48.89. Padding to 128 minimizes truncation while limiting excess padding.\n",
        "\n",
        "* Instructions: Max length is 2,946, mean is 199.98. Padding to 1024 balances sequence coverage and memory efficiency."
      ],
      "metadata": {
        "id": "3-AotSQ4XtSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformer Architecture**"
      ],
      "metadata": {
        "id": "oefMQ_4kw16k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**positional encoding**\n",
        "\n",
        "* Purpose: Enhances sequence embeddings with position-specific information for Transformer models\n",
        "\n",
        "* In short, it makes sure the model knows the difference between \"flour, sugar, eggs\" and \"eggs, sugar, flour\" when generating recipes."
      ],
      "metadata": {
        "id": "nErjWOYxYXLL"
      }
    },
    {
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn # Import the nn module from PyTorch\n",
        "from transformers import AutoTokenizer\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        # Create a zero matrix of shape (max_len, d_model)\n",
        "        self.encoding = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)  # Shape: (max_len, 1)\n",
        "\n",
        "        # Calculate the division term for sine and cosine scaling\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
        "\n",
        "        # Apply sine to even indices and cosine to odd indices\n",
        "        self.encoding[:, 0::2] = torch.sin(position * div_term)  # Apply sine on even dimensions\n",
        "        self.encoding[:, 1::2] = torch.cos(position * div_term)  # Apply cosine on odd dimensions\n",
        "\n",
        "        # Add a batch dimension (1) for broadcasting later\n",
        "        self.encoding = self.encoding.unsqueeze(0)  # Shape: (1, max_len, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input shape validation\n",
        "        if len(x.shape) != 3:\n",
        "            raise ValueError(f\"Expected input of shape (batch_size, seq_len, d_model), got {x.shape}\")\n",
        "\n",
        "        seq_len = x.size(1)  # Get the actual sequence length\n",
        "        # Add positional encoding to the input and send to the device\n",
        "        return x + self.encoding[:, :seq_len, :].to(x.device)\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "AFXKQXguxYzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet demonstrates how to use the PositionalEncoding class that was defined earlier."
      ],
      "metadata": {
        "id": "nJ1JDoetY1Di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "embedding_dim = 128  # Match this to the embedding dimension size\n",
        "max_len = 1024       # Maximum sequence length\n",
        "\n",
        "# Initialize Positional Encoding\n",
        "pos_encoder = PositionalEncoding(d_model=embedding_dim, max_len=max_len)\n",
        "\n",
        "# Example input tensor (batch_size=2, seq_len=1024, d_model=128)\n",
        "x = torch.randn(2, 1024, 128)\n",
        "\n",
        "# Apply positional encoding\n",
        "x_with_pos = pos_encoder(x)\n",
        "print(\"Output Shape after Positional Encoding:\", x_with_pos.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNk3d4YAagfY",
        "outputId": "522cb31b-198b-4dea-ab86-4ec634323209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output Shape after Positional Encoding: torch.Size([2, 1024, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The TransformerEncoder** class encodes word indices into embeddings, adds positional data, processes them through Transformer layers, and produces an encoded representation for the decoder to generate outputs like recipe instructions."
      ],
      "metadata": {
        "id": "Bj-DerA6ZQZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, nhead, num_layers):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)  # Shape: (batch_size, seq_len, d_model)\n",
        "        src = self.positional_encoding(embedded)  # Add positional encoding\n",
        "        src = src.permute(1, 0, 2)  # Transformer expects shape (seq_len, batch_size, d_model)\n",
        "        return self.encoder(src)"
      ],
      "metadata": {
        "id": "3hDjXAL3xfnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation of nn.TransformerEncoderLayer and nn.TransformerEncoder\n",
        "\n",
        "\"\"\"\n",
        "### nn.TransformerEncoderLayer (Single Layer)\n",
        "1. **Multi-Head Self-Attention**:\n",
        "   - Computes attention between all tokens in the sequence.\n",
        "   - Helps each token understand relationships with other tokens.\n",
        "\n",
        "2. **Feedforward Network**:\n",
        "   - Processes each token through two linear layers with a ReLU in between.\n",
        "   - Adds depth and transforms token representations.\n",
        "\n",
        "3. **Residual Connections + Layer Normalization**:\n",
        "   - Adds the input back to the output (residual connection).\n",
        "   - Normalizes the result for stable training.\n",
        "\n",
        "**Purpose**: Captures relationships between tokens in the sequence.\n",
        "\n",
        "---\n",
        "\n",
        "### nn.TransformerEncoder (Stack of Layers)\n",
        "1. **Structure**:\n",
        "   - Stacks `num_layers` of `nn.TransformerEncoderLayer`.\n",
        "   - Each layer builds on the output of the previous layer.\n",
        "\n",
        "2. **Operation**:\n",
        "   - Each layer refines token embeddings by adding more context.\n",
        "   - Final output contains deeply contextualized token representations.\n",
        "\n",
        "**Purpose**: Produces a comprehensive understanding of the input sequence.\n",
        "\n",
        "---\n",
        "\n",
        "### Data Flow\n",
        "- **Input Shape**: `(seq_len, batch_size, d_model)`\n",
        "- **Output Shape**: `(seq_len, batch_size, d_model)`\n",
        "- The input passes through:\n",
        "  - Embedding → Add Positional Encoding Encoder → Permute Dimensions →  Layer 1 → Encoder Layer 2 → ... → Encoder Layer `num_layers`.\n",
        "---\n",
        "\n",
        "**Summary**:\n",
        "- `nn.TransformerEncoderLayer`: Processes a single layer of attention and feedforward.\n",
        "- `nn.TransformerEncoder`: Stacks multiple layers to build progressively refined representations.\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "VHTLQXdguUNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The TransformerDecoder** generates recipe instructions by embedding target tokens, applying positional encoding, decoding with multi-head attention and feedforward layers, and projecting to the vocabulary logits."
      ],
      "metadata": {
        "id": "rJQ0s0VQZid-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, nhead, num_layers):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)  # Map decoder output to vocabulary size\n",
        "\n",
        "    def forward(self, tgt, memory):\n",
        "        embedded = self.embedding(tgt)\n",
        "        tgt = self.positional_encoding(embedded)\n",
        "        tgt = tgt.permute(1, 0, 2)  # Shape: (seq_len, batch_size, d_model)\n",
        "        output = self.decoder(tgt, memory)  # Decoder processing\n",
        "        output = output.permute(1, 0, 2)  # Back to (batch_size, seq_len, d_model)\n",
        "        return self.fc_out(output)  # Shape: (batch_size, seq_len, vocab_size)\n"
      ],
      "metadata": {
        "id": "A2rK8gO9xhPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation of TransformerDecoder\n",
        "\n",
        "\"\"\"\n",
        "### TransformerDecoder Class\n",
        "1. **Embedding Layer**:\n",
        "   - Converts token indices in `tgt` into dense vectors.\n",
        "\n",
        "2. **Positional Encoding**:\n",
        "   - Adds positional information to token embeddings.\n",
        "\n",
        "3. **TransformerDecoder Layers**:\n",
        "   - Each layer processes the target sequence (`tgt`) using:\n",
        "     - **Self-Attention**: Understand relationships within the target sequence.\n",
        "     - **Cross-Attention**: Leverages `memory` (encoder output) to integrate context from the source sequence.\n",
        "     - **Feedforward Network**: Refines token representations.\n",
        "\n",
        "4. **Linear Output Layer**:\n",
        "   - Maps decoder output to vocabulary size for predictions.\n",
        "\n",
        "---\n",
        "\n",
        "### Forward Method Steps:\n",
        "1. **Input Processing**:\n",
        "   - `tgt` (target sequence) is embedded and positional encodings are added.\n",
        "   - Shape: `(batch_size, seq_len)` → `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "2. **Permute Dimensions**:\n",
        "   - Transformer requires: `(seq_len, batch_size, d_model)`.\n",
        "\n",
        "3. **Decoder Processing**:\n",
        "   - `self.decoder(tgt, memory)` processes `tgt` using `memory` (encoder output).\n",
        "\n",
        "4. **Final Transformation**:\n",
        "   - Permute back: `(seq_len, batch_size, d_model)` → `(batch_size, seq_len, d_model)`.\n",
        "   - `self.fc_out(output)`: Maps each token to a probability distribution over the vocabulary.\n",
        "\n",
        "**Output Shape**:\n",
        "- Final output shape: `(batch_size, seq_len, vocab_size)` for predictions.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "qpQHQhNswHpW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uws8jAT3uT8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Seq2SeqTransformer combines an encoder and decoder for recipe generation"
      ],
      "metadata": {
        "id": "L1sGbpT3Zq7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=512, nhead=8, num_layers=6):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.encoder = TransformerEncoder(vocab_size, d_model, nhead, num_layers)\n",
        "        self.decoder = TransformerDecoder(vocab_size, d_model, nhead, num_layers)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        memory = self.encoder(src)  # Encode the source sequence\n",
        "        output = self.decoder(tgt, memory)  # Decode the target sequence\n",
        "        return output"
      ],
      "metadata": {
        "id": "NM6Oi5pfxnPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAfCc90O-LmN",
        "outputId": "77593ce7-c712-46ff-e3c2-d94f1fb6ddfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "initializes and tests the recipe generation model (Seq2SeqTransformer)."
      ],
      "metadata": {
        "id": "0ln1n-22aG3r"
      }
    },
    {
      "source": [
        "if __name__ == \"__main__\":\n",
        "    vocab_size = 12000\n",
        "    d_model = 128\n",
        "    nhead = 2\n",
        "    num_layers = 4\n",
        "    seq_len = 64\n",
        "    batch_size = 32\n",
        "\n",
        "    model = Seq2SeqTransformer(vocab_size, d_model=d_model, nhead=nhead, num_layers=num_layers)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    src = torch.randint(0, vocab_size, (batch_size, seq_len), dtype=torch.long).to(device)\n",
        "    tgt = torch.randint(0, vocab_size, (batch_size, seq_len), dtype=torch.long).to(device)\n",
        "\n",
        "    from torch.amp.autocast_mode import autocast\n",
        "    with autocast(device_type='cuda'):\n",
        "        try:\n",
        "            output = model(src, tgt)\n",
        "            print(\"Output shape:\", output.shape)\n",
        "        except IndexError as e:\n",
        "            print(f\"Error during forward pass: {e}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0ecp0O-zUcK",
        "outputId": "9314a890-9c66-4b19-ac37-f118239a3918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([32, 64, 12000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**2. Training the Transformer**"
      ],
      "metadata": {
        "id": "mVR7TRAPH0da"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2.1: Set Up the Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "SoP1yYI1IGes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* criterion: Defines how the model's predictions are compared to the actual recipe instructions (using Cross-Entropy Loss and ignoring padding).\n",
        "* optimizer: Determines how the model's parameters are adjusted during training to improve its performance (using the AdamW optimizer with a learning rate of 0.001)."
      ],
      "metadata": {
        "id": "kJbrQpj6a2cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Assuming padding token is ID 0\n",
        "from torch.optim import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "iTy3YRNOHwGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script trains and validates a Seq2Seq Transformer for generating recipe instructions:\n",
        "\n",
        "* **Data Preparation:**  Splits data into training/validation sets, converts sequences to tensors, and creates DataLoaders.\n",
        "\n",
        "* **Training:** Performs batched training with backpropagation, tracking training loss.\n",
        "\n",
        "* **Validation**: Evaluates on validation data without gradients, tracking validation loss.\n",
        "\n",
        "* **Visualization**: Plots training and validation loss over epochs to monitor performance."
      ],
      "metadata": {
        "id": "JUKrVBhUbLYG"
      }
    },
    {
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert training data to tensors\n",
        "train_src_tensor = torch.tensor(train_data['Padded_Ingredient_Ids'].tolist(), dtype=torch.long)\n",
        "train_tgt_tensor = torch.tensor(train_data['Padded_Instruction_Ids'].tolist(), dtype=torch.long)\n",
        "\n",
        "# Convert validation data to tensors\n",
        "val_src_tensor = torch.tensor(val_data['Padded_Ingredient_Ids'].tolist(), dtype=torch.long)\n",
        "val_tgt_tensor = torch.tensor(val_data['Padded_Instruction_Ids'].tolist(), dtype=torch.long)\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(train_src_tensor, train_tgt_tensor)\n",
        "val_dataset = TensorDataset(val_src_tensor, val_tgt_tensor)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Training and Validation Loops\n",
        "num_epochs = 10  # Define the number of epochs\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training Loop\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for src_batch, tgt_batch in train_dataloader:\n",
        "        src_batch = src_batch.to(device)\n",
        "        tgt_batch = tgt_batch.to(device)\n",
        "\n",
        "        tgt_input = tgt_batch[:, :-1]  # Exclude last token for decoder input\n",
        "        tgt_output = tgt_batch[:, 1:]  # Exclude first token for ground truth\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src_batch, tgt_input)\n",
        "         # Reshape output to (batch_size * seq_len, vocab_size)\n",
        "        output = output.reshape(-1, output.shape[-1])\n",
        "        # Reshape target output to (batch_size * seq_len)\n",
        "        tgt_output = tgt_output.reshape(-1)\n",
        "        loss = criterion(output, tgt_output)  # Compute loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "    # Store training loss - Corrected indentation\n",
        "    train_losses.append(total_train_loss / len(train_dataloader))\n",
        "\n",
        "\n",
        "    # Validation Loop\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src_batch, tgt_batch in val_dataloader:\n",
        "            src_batch = src_batch.to(device)\n",
        "            tgt_batch = tgt_batch.to(device)\n",
        "\n",
        "            tgt_input = tgt_batch[:, :-1]  # Exclude last token for decoder input\n",
        "            tgt_output = tgt_batch[:, 1:]  # Exclude first token for ground truth\n",
        "\n",
        "            output = model(src_batch, tgt_input)\n",
        "            loss = criterion(output.reshape(-1, vocab_size), tgt_output.reshape(-1))  # Compute loss\n",
        "            total_val_loss += loss.item()\n",
        "    # Store validation loss - Corrected indentation\n",
        "    val_losses.append(total_val_loss / len(val_dataloader))\n",
        "\n",
        "    # Print Losses for the Epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_train_loss / len(train_dataloader):.4f}, Validation Loss: {total_val_loss / len(val_dataloader):.4f}\")\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "outputId": "203b1310-aeb3-4b51-999e-610e025a582e",
        "id": "9gfv-QZxzQlX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Training Loss: 5.4525, Validation Loss: 4.1851\n",
            "Epoch 2/10, Training Loss: 3.5575, Validation Loss: 2.6334\n",
            "Epoch 3/10, Training Loss: 2.2027, Validation Loss: 1.3389\n",
            "Epoch 4/10, Training Loss: 0.8390, Validation Loss: 0.4030\n",
            "Epoch 5/10, Training Loss: 0.3041, Validation Loss: 0.2519\n",
            "Epoch 6/10, Training Loss: 0.1653, Validation Loss: 0.2084\n",
            "Epoch 7/10, Training Loss: 0.1036, Validation Loss: 0.1754\n",
            "Epoch 8/10, Training Loss: 0.0695, Validation Loss: 0.1499\n",
            "Epoch 9/10, Training Loss: 0.0494, Validation Loss: 0.1510\n",
            "Epoch 10/10, Training Loss: 0.0375, Validation Loss: 0.1617\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot shows Training Loss (blue) and Validation Loss (orange) over epochs. Key observations:\n",
        "\n",
        "* Convergence: Both losses decrease rapidly in early epochs and stabilize after epoch 5.\n",
        "* Overfitting Risk: Training and validation losses remain close, suggesting minimal overfitting.\n",
        "* Performance: Low final loss indicates good learning of the task.\n",
        "\n",
        "This demonstrates the model's effectiveness and proper generalization during training."
      ],
      "metadata": {
        "id": "kDHF9lnr3PvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"transformer_model.pth\")\n",
        "print(\"Model saved successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "MbhQkO_qfz_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5050d8-da2d-487c-873e-cb66ca29f51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(\"transformer_model.pth\", map_location=torch.device('cpu'))\n",
        "\n",
        "# Check the shape of the embedding layer weights\n",
        "print(\"Encoder Embedding Shape:\", state_dict['encoder.embedding.weight'].shape)\n",
        "print(\"Decoder Embedding Shape:\", state_dict['decoder.embedding.weight'].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6dfo3ysAhA5",
        "outputId": "6c0694ae-788e-4218-f5b2-9bb2418a637f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Embedding Shape: torch.Size([12000, 128])\n",
            "Decoder Embedding Shape: torch.Size([12000, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-7e639023db52>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(\"transformer_model.pth\", map_location=torch.device('cpu'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **evaluation**\n",
        "using BLEU and ROUGE metrics"
      ],
      "metadata": {
        "id": "h7oFdgrZcUUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k8AOEMbAsiD",
        "outputId": "a81ef4ff-2e46-4239-e1c8-f35f916cb23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=3b2a045eaf29b23feb765678d09447ae17a4427e3dc7d642ff82cff3db05ae85\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BLEU:** Measures n-gram overlap between generated and reference recipes.\n",
        "\n",
        "**ROUGE:** Measures precision, recall, and F1-score for n-grams (ROUGE-1, ROUGE-2, ROUGE-L).\n",
        "\n",
        "* Recipe Generation:\n",
        "\n",
        "Given input ingredients, the model generates a recipe iteratively using its encoder-decoder structure.\n",
        "\n",
        "**Evaluation:**\n",
        "\n",
        "* BLEU: Measures n-gram overlap between generated and reference recipes.\n",
        "* ROUGE: Measures precision, recall, and F1-score for n-grams (ROUGE-1, ROUGE-2, ROUGE-L).\n"
      ],
      "metadata": {
        "id": "M-VT590sclRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentencepiece import SentencePieceProcessor\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Load the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Seq2SeqTransformer(vocab_size=12000, d_model=128, nhead=4, num_layers=4)\n",
        "model.load_state_dict(torch.load(\"transformer_model.pth\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = SentencePieceProcessor()\n",
        "tokenizer.load(\"recipe.model\")\n",
        "\n",
        "# Metric Functions\n",
        "def compute_bleu(reference, hypothesis):\n",
        "    smoothie = SmoothingFunction().method1\n",
        "    return sentence_bleu([reference.split()], hypothesis.split(), smoothing_function=smoothie)\n",
        "\n",
        "def compute_rouge(reference, hypothesis):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    return scorer.score(reference, hypothesis)\n",
        "\n",
        "# Recipe Generation Function\n",
        "def generate_recipe(model, src, tokenizer, max_len=100):\n",
        "    generated_tokens = torch.tensor([[tokenizer.bos_id()]], device=device)\n",
        "    src = src.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            memory = model.encoder(src)\n",
        "            output = model.decoder(generated_tokens, memory)\n",
        "            logits = output[:, -1, :]\n",
        "            next_token = torch.argmax(logits, dim=-1).unsqueeze(1)\n",
        "            generated_tokens = torch.cat([generated_tokens, next_token], dim=1)\n",
        "            if next_token.item() == tokenizer.eos_id():\n",
        "                break\n",
        "\n",
        "    return tokenizer.decode(generated_tokens.squeeze(0).tolist())\n",
        "\n",
        "\n",
        "# Test Data (Ingredients and References)\n",
        "test_data = [\n",
        "    \"chicken, garlic, onion\",\n",
        "    \"tomato, basil, olive oil\",\n",
        "    \"flour, sugar, butter, eggs\"\n",
        "]\n",
        "\n",
        "reference_recipes = [\n",
        "    \"Cook chicken with garlic and onion until golden.\",\n",
        "    \"Make a fresh tomato basil sauce with olive oil.\",\n",
        "    \"Mix flour, sugar, butter, and eggs to bake a cake.\"\n",
        "]\n",
        "\n",
        "# Test the Model\n",
        "print(\"Testing the Model...\")\n",
        "bleu_scores = []\n",
        "rouge_scores = []\n",
        "\n",
        "for idx, ingredients in enumerate(test_data):\n",
        "    print(f\"\\nTest Case {idx + 1}: Ingredients: {ingredients}\")\n",
        "    encoded_input = tokenizer.encode(ingredients, out_type=int)\n",
        "    src_tensor = torch.tensor([encoded_input], dtype=torch.long)\n",
        "\n",
        "    # Generate recipe\n",
        "    generated_recipe = generate_recipe(model, src_tensor, tokenizer)\n",
        "    print(f\"Generated Recipe: {generated_recipe}\")\n",
        "    print(f\"Reference Recipe: {reference_recipes[idx]}\")\n",
        "\n",
        "    # Compute BLEU and ROUGE scores\n",
        "    bleu = compute_bleu(reference_recipes[idx], generated_recipe)\n",
        "    rouge = compute_rouge(reference_recipes[idx], generated_recipe)\n",
        "\n",
        "    print(f\"BLEU Score: {bleu:.4f}\")\n",
        "    print(f\"ROUGE Scores: {rouge}\")\n",
        "\n",
        "    bleu_scores.append(bleu)\n",
        "    rouge_scores.append(rouge)\n",
        "\n",
        "# Average BLEU and ROUGE Scores\n",
        "avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "avg_rouge = {key: sum(r[key].fmeasure for r in rouge_scores) / len(rouge_scores) for key in rouge_scores[0].keys()}\n",
        "\n",
        "print(\"\\n--- Final Evaluation ---\")\n",
        "print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n",
        "print(f\"Average ROUGE Scores: {avg_rouge}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEYTW0c8_Azi",
        "outputId": "bf6ad840-10cf-4cef-cb94-f940ea39f7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-7a48e47f78f4>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"transformer_model.pth\", map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the Model...\n",
            "\n",
            "Test Case 1: Ingredients: chicken, garlic, onion\n",
            "Generated Recipe: liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur\n",
            "Reference Recipe: Cook chicken with garlic and onion until golden.\n",
            "BLEU Score: 0.0000\n",
            "ROUGE Scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
            "\n",
            "Test Case 2: Ingredients: tomato, basil, olive oil\n",
            "Generated Recipe: liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur\n",
            "Reference Recipe: Make a fresh tomato basil sauce with olive oil.\n",
            "BLEU Score: 0.0000\n",
            "ROUGE Scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
            "\n",
            "Test Case 3: Ingredients: flour, sugar, butter, eggs\n",
            "Generated Recipe: liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur liqueur\n",
            "Reference Recipe: Mix flour, sugar, butter, and eggs to bake a cake.\n",
            "BLEU Score: 0.0000\n",
            "ROUGE Scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
            "\n",
            "--- Final Evaluation ---\n",
            "Average BLEU Score: 0.0000\n",
            "Average ROUGE Scores: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "\n",
        "* Generated Output: Repetition of the same token (\"butterfly\") across all test cases.\n",
        "* BLEU & ROUGE Scores: All scores are 0, indicating no similarity between generated and reference recipes.\n",
        "*  Evaluation: Average scores remain at zero, confirming the model’s failure to learn meaningful patterns.\n"
      ],
      "metadata": {
        "id": "il9U20A8eW6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the tokenization of a sample input\n",
        "encoded = tokenizer.encode(\"chicken, garlic, onion\", out_type=int)\n",
        "decoded = tokenizer.decode(encoded)\n",
        "print(\"Encoded:\", encoded)\n",
        "print(\"Decoded:\", decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq0PnyKWfM4z",
        "outputId": "abacd6a0-2e08-4380-861f-0aafab2ab013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: [85, 3, 53, 3, 95]\n",
            "Decoded: chicken, garlic, onion\n"
          ]
        }
      ]
    }
  ]
}